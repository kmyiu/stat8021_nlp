{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eaecb33-82a6-4210-a37b-e3121ef2373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import evaluate\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(8021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b395ed3-9c22-4050-855b-51d84f019f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv('HC3.csv')\n",
    "input_data = input_data.dropna()\n",
    "input_data = input_data.sample(frac=1)\n",
    "\n",
    "manual_data = pd.read_excel('test_set.xlsx')\n",
    "\n",
    "input_data['question'] = input_data['question'].str.lower()\n",
    "input_data['answers'] = input_data['answers'].str.lower()\n",
    "manual_data['question'] = manual_data['question'].str.lower()\n",
    "manual_data['answers'] = manual_data['answers'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2422f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data['q'] = input_data['question'].map(lambda x : nltk.tokenize.word_tokenize(x))\n",
    "input_data['a'] = input_data['answers'].map(lambda x : nltk.tokenize.word_tokenize(x))\n",
    "\n",
    "manual_data['q'] = manual_data['question'].map(lambda x : nltk.tokenize.word_tokenize(x))\n",
    "manual_data['a'] = manual_data['answers'].map(lambda x : nltk.tokenize.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a93c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init Word2Vec model\n",
    "\n",
    "word2vec_vector_size = 25\n",
    "\n",
    "all_words1 = input_data['q'] + input_data['a']\n",
    "all_words2 = manual_data['q'] + manual_data['a']\n",
    "all_words = pd.concat([all_words1, all_words2], axis=0)\n",
    "\n",
    "word2vec_model = Word2Vec(sentences=all_words, vector_size=word2vec_vector_size, window=5, min_count=1, workers=4)\n",
    "word2vec_model.save(\"word2vec_lstm.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd405d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "question_max_len = 100\n",
    "answer_max_len = 400\n",
    "text_max_len = question_max_len + answer_max_len\n",
    "# include question flag\n",
    "include_question = False\n",
    "sentence_max_len = question_max_len + answer_max_len if include_question else answer_max_len\n",
    "    \n",
    "def get_embedding(row):\n",
    "    # embedding for q\n",
    "    if include_question:\n",
    "        q = row['q']\n",
    "        if len(q) > question_max_len:\n",
    "            q = q[0:question_max_len]\n",
    "        embedding_q = word2vec_model.wv[q]\n",
    "        if len(q) < question_max_len:\n",
    "            embedding_q = np.concatenate([embedding_q, np.zeros((question_max_len - len(q), word2vec_vector_size))])\n",
    "\n",
    "    # embedding for a\n",
    "    a = row['a']\n",
    "    if len(a) > answer_max_len:\n",
    "        a = a[0:answer_max_len]\n",
    "    embedding_a = word2vec_model.wv[a]\n",
    "    \n",
    "    if len(a) < answer_max_len:\n",
    "        embedding_a = np.concatenate([embedding_a, np.zeros((answer_max_len - len(a), word2vec_vector_size))])\n",
    "\n",
    "    if include_question:\n",
    "        embedding = np.concatenate([embedding_q, embedding_a])\n",
    "    else:\n",
    "        embedding = embedding_a\n",
    "\n",
    "    embedding = np.array(embedding, dtype='float')\n",
    "\n",
    "    return embedding\n",
    "\n",
    "# add column for embedding\n",
    "input_data['embedding'] = np.nan\n",
    "\n",
    "embeddings = list()\n",
    "for index, row in input_data.iterrows():\n",
    "    try:\n",
    "        embeddings.append(get_embedding(row))\n",
    "    except Exception as err:\n",
    "        pass\n",
    "        print(err)\n",
    "\n",
    "# put embedding into dataframe\n",
    "input_data['embedding'] = embeddings\n",
    "\n",
    "manual_data['embedding'] = np.nan\n",
    "embeddings_manual = list()\n",
    "for index, row in manual_data.iterrows():\n",
    "    try:\n",
    "        embeddings_manual.append(get_embedding(row))\n",
    "    except Exception as err:\n",
    "        pass\n",
    "        print(err)\n",
    "\n",
    "# put embedding into dataframe\n",
    "manual_data['embedding'] = embeddings_manual"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae7cfa63",
   "metadata": {},
   "source": [
    "### Display input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87e5a9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23865"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d98a97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets with a 80:20 split\n",
    "train_data, test_data = train_test_split(input_data, test_size=0.2)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "921b0ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>source</th>\n",
       "      <th>labels</th>\n",
       "      <th>answers</th>\n",
       "      <th>q</th>\n",
       "      <th>a</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intentions of deductible amount for small busi...</td>\n",
       "      <td>finance</td>\n",
       "      <td>0</td>\n",
       "      <td>if your sole proprietorship losses exceed all ...</td>\n",
       "      <td>[intentions, of, deductible, amount, for, smal...</td>\n",
       "      <td>[if, your, sole, proprietorship, losses, excee...</td>\n",
       "      <td>[[3.9413859844207764, 2.8509163856506348, 0.35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high leverage inflation hedges for personal in...</td>\n",
       "      <td>finance</td>\n",
       "      <td>0</td>\n",
       "      <td>i assume you're looking for advice, not an act...</td>\n",
       "      <td>[high, leverage, inflation, hedges, for, perso...</td>\n",
       "      <td>[i, assume, you, 're, looking, for, advice, ,,...</td>\n",
       "      <td>[[1.693681240081787, -3.0884225368499756, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>are there tax liabilities (in the us) for havi...</td>\n",
       "      <td>finance</td>\n",
       "      <td>1</td>\n",
       "      <td>if you are a us citizen or a resident alien an...</td>\n",
       "      <td>[are, there, tax, liabilities, (, in, the, us,...</td>\n",
       "      <td>[if, you, are, a, us, citizen, or, a, resident...</td>\n",
       "      <td>[[3.9413859844207764, 2.8509163856506348, 0.35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how is it possible for humans to \" lose \" or d...</td>\n",
       "      <td>reddit_eli5</td>\n",
       "      <td>0</td>\n",
       "      <td>he means the us does n't have a ready - to - g...</td>\n",
       "      <td>[how, is, it, possible, for, humans, to, ``, l...</td>\n",
       "      <td>[he, means, the, us, does, n't, have, a, ready...</td>\n",
       "      <td>[[-0.5366077423095703, -3.5822958946228027, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>why does a computer need to be cooled ? why ca...</td>\n",
       "      <td>reddit_eli5</td>\n",
       "      <td>1</td>\n",
       "      <td>computers generate heat because they have elec...</td>\n",
       "      <td>[why, does, a, computer, need, to, be, cooled,...</td>\n",
       "      <td>[computers, generate, heat, because, they, hav...</td>\n",
       "      <td>[[-2.278885841369629, -0.0902240127325058, 1.6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question       source  labels   \n",
       "0  intentions of deductible amount for small busi...      finance       0  \\\n",
       "1  high leverage inflation hedges for personal in...      finance       0   \n",
       "2  are there tax liabilities (in the us) for havi...      finance       1   \n",
       "3  how is it possible for humans to \" lose \" or d...  reddit_eli5       0   \n",
       "4  why does a computer need to be cooled ? why ca...  reddit_eli5       1   \n",
       "\n",
       "                                             answers   \n",
       "0  if your sole proprietorship losses exceed all ...  \\\n",
       "1  i assume you're looking for advice, not an act...   \n",
       "2  if you are a us citizen or a resident alien an...   \n",
       "3  he means the us does n't have a ready - to - g...   \n",
       "4  computers generate heat because they have elec...   \n",
       "\n",
       "                                                   q   \n",
       "0  [intentions, of, deductible, amount, for, smal...  \\\n",
       "1  [high, leverage, inflation, hedges, for, perso...   \n",
       "2  [are, there, tax, liabilities, (, in, the, us,...   \n",
       "3  [how, is, it, possible, for, humans, to, ``, l...   \n",
       "4  [why, does, a, computer, need, to, be, cooled,...   \n",
       "\n",
       "                                                   a   \n",
       "0  [if, your, sole, proprietorship, losses, excee...  \\\n",
       "1  [i, assume, you, 're, looking, for, advice, ,,...   \n",
       "2  [if, you, are, a, us, citizen, or, a, resident...   \n",
       "3  [he, means, the, us, does, n't, have, a, ready...   \n",
       "4  [computers, generate, heat, because, they, hav...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [[3.9413859844207764, 2.8509163856506348, 0.35...  \n",
       "1  [[1.693681240081787, -3.0884225368499756, -0.2...  \n",
       "2  [[3.9413859844207764, 2.8509163856506348, 0.35...  \n",
       "3  [[-0.5366077423095703, -3.5822958946228027, 0....  \n",
       "4  [[-2.278885841369629, -0.0902240127325058, 1.6...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd618b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>source</th>\n",
       "      <th>labels</th>\n",
       "      <th>answers</th>\n",
       "      <th>q</th>\n",
       "      <th>a</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>why do people see proprietary software as bad ...</td>\n",
       "      <td>reddit_eli5</td>\n",
       "      <td>0</td>\n",
       "      <td>there are those that believe if everything was...</td>\n",
       "      <td>[why, do, people, see, proprietary, software, ...</td>\n",
       "      <td>[there, are, those, that, believe, if, everyth...</td>\n",
       "      <td>[[4.366678714752197, -2.834803342819214, 3.286...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>please explain what is \"cyber defence\"</td>\n",
       "      <td>wiki_csai</td>\n",
       "      <td>0</td>\n",
       "      <td>proactive cyber defence means acting in antici...</td>\n",
       "      <td>[please, explain, what, is, ``, cyber, defence...</td>\n",
       "      <td>[proactive, cyber, defence, means, acting, in,...</td>\n",
       "      <td>[[0.11999265849590302, -0.47481417655944824, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how are digestion processes different for suga...</td>\n",
       "      <td>reddit_eli5</td>\n",
       "      <td>0</td>\n",
       "      <td>the body is fueled by monosacchirides such as ...</td>\n",
       "      <td>[how, are, digestion, processes, different, fo...</td>\n",
       "      <td>[the, body, is, fueled, by, monosacchirides, s...</td>\n",
       "      <td>[[1.0252605676651, -0.29854241013526917, -0.70...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is object oriented code ? i 've heard it ...</td>\n",
       "      <td>reddit_eli5</td>\n",
       "      <td>0</td>\n",
       "      <td>object oriented code is a way of building a pr...</td>\n",
       "      <td>[what, is, object, oriented, code, ?, i, 've, ...</td>\n",
       "      <td>[object, oriented, code, is, a, way, of, build...</td>\n",
       "      <td>[[-0.35408398509025574, 4.469900608062744, -2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>should i use a bank or a credit union for my s...</td>\n",
       "      <td>finance</td>\n",
       "      <td>0</td>\n",
       "      <td>in practical terms, these days, a credit union...</td>\n",
       "      <td>[should, i, use, a, bank, or, a, credit, union...</td>\n",
       "      <td>[in, practical, terms, ,, these, days, ,, a, c...</td>\n",
       "      <td>[[1.08537757396698, 1.732524037361145, 3.03414...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question       source  labels   \n",
       "0  why do people see proprietary software as bad ...  reddit_eli5       0  \\\n",
       "1             please explain what is \"cyber defence\"    wiki_csai       0   \n",
       "2  how are digestion processes different for suga...  reddit_eli5       0   \n",
       "3  what is object oriented code ? i 've heard it ...  reddit_eli5       0   \n",
       "4  should i use a bank or a credit union for my s...      finance       0   \n",
       "\n",
       "                                             answers   \n",
       "0  there are those that believe if everything was...  \\\n",
       "1  proactive cyber defence means acting in antici...   \n",
       "2  the body is fueled by monosacchirides such as ...   \n",
       "3  object oriented code is a way of building a pr...   \n",
       "4  in practical terms, these days, a credit union...   \n",
       "\n",
       "                                                   q   \n",
       "0  [why, do, people, see, proprietary, software, ...  \\\n",
       "1  [please, explain, what, is, ``, cyber, defence...   \n",
       "2  [how, are, digestion, processes, different, fo...   \n",
       "3  [what, is, object, oriented, code, ?, i, 've, ...   \n",
       "4  [should, i, use, a, bank, or, a, credit, union...   \n",
       "\n",
       "                                                   a   \n",
       "0  [there, are, those, that, believe, if, everyth...  \\\n",
       "1  [proactive, cyber, defence, means, acting, in,...   \n",
       "2  [the, body, is, fueled, by, monosacchirides, s...   \n",
       "3  [object, oriented, code, is, a, way, of, build...   \n",
       "4  [in, practical, terms, ,, these, days, ,, a, c...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [[4.366678714752197, -2.834803342819214, 3.286...  \n",
       "1  [[0.11999265849590302, -0.47481417655944824, 0...  \n",
       "2  [[1.0252605676651, -0.29854241013526917, -0.70...  \n",
       "3  [[-0.35408398509025574, 4.469900608062744, -2....  \n",
       "4  [[1.08537757396698, 1.732524037361145, 3.03414...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ab74478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyrus\\AppData\\Local\\Temp\\ipykernel_2360\\4050078855.py:18: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  training_set = Dataset(torch.tensor(train_data['embedding'], dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, embedding, labels):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.embedding = embedding\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'    \n",
    "        X = self.embedding[index]\n",
    "        y = self.labels[index]\n",
    "        return X, y\n",
    "\n",
    "training_set = Dataset(torch.tensor(train_data['embedding'], dtype=torch.float32)\n",
    "                         , torch.tensor(train_data['labels'].to_numpy(), dtype=torch.float32))\n",
    "\n",
    "validation_set = Dataset(torch.tensor(test_data['embedding'], dtype=torch.float32)\n",
    "                         , torch.tensor(test_data['labels'].to_numpy(), dtype=torch.float32))\n",
    "\n",
    "manual_set = Dataset(torch.tensor(manual_data['embedding'], dtype=torch.float32)\n",
    "                         , torch.tensor(manual_data['labels'].to_numpy(), dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9be1ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(validation_set, batch_size=batch_size, shuffle=True)\n",
    "manual_dataloader = DataLoader(manual_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1375888",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4950b201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9670c94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, num_classes=1):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, hidden_size, num_layers, batch_first=True, bidirectional=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "        # replace softmax by sigmoid for binary classification\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        out, (final_hidden_state, final_cell_state) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.sigmoid(out)\n",
    "        return out.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11b4f95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [01/20], Training Loss: 0.6781, Testing accuracy: 0.5248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [02/20], Training Loss: 0.6736, Testing accuracy: 0.5307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [03/20], Training Loss: 0.6415, Testing accuracy: 0.5081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [04/20], Training Loss: 0.3900, Testing accuracy: 0.8864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [05/20], Training Loss: 0.1783, Testing accuracy: 0.9434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [06/20], Training Loss: 0.1165, Testing accuracy: 0.9560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [07/20], Training Loss: 0.0919, Testing accuracy: 0.9581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [08/20], Training Loss: 0.0693, Testing accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [09/20], Training Loss: 0.0644, Testing accuracy: 0.9679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Training Loss: 0.0553, Testing accuracy: 0.9629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Training Loss: 0.0519, Testing accuracy: 0.9583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Training Loss: 0.0448, Testing accuracy: 0.9728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Training Loss: 0.0332, Testing accuracy: 0.9709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Training Loss: 0.0367, Testing accuracy: 0.9751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Training Loss: 0.0306, Testing accuracy: 0.9728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Training Loss: 0.0421, Testing accuracy: 0.9571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Training Loss: 0.0322, Testing accuracy: 0.9728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Training Loss: 0.0247, Testing accuracy: 0.9738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Training Loss: 0.0235, Testing accuracy: 0.9721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Training Loss: 0.0274, Testing accuracy: 0.9753\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "input_dim = word2vec_vector_size\n",
    "model = BiLSTM(input_dim, 200).to(device)\n",
    "\n",
    "# attempt to use 0.1, bad, 0.01 a bit fast, 0.0001 do not converge\n",
    "learning_rate = 0.005\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 20\n",
    "training_lost = dict()\n",
    "\n",
    "# Train Bi-LSTM\n",
    "total_steps = len(train_dataloader)\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for index, (embedding, labels) in tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=f\"Epoch {epoch:02d}\", leave=False):\n",
    "\n",
    "        embedding = embedding.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(embedding)        \n",
    "        outputs = torch.squeeze(outputs).float()\n",
    "\n",
    "        labels = torch.squeeze(labels).float()\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "        \n",
    "    # Testing\n",
    "    test_preds = []\n",
    "    test_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch in val_dataloader:\n",
    "\n",
    "            embedding, labels = batch\n",
    "            embedding = embedding.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(embedding)\n",
    "\n",
    "            test_preds.append(outputs.cpu().numpy())\n",
    "            test_labels.append(labels.cpu().numpy())\n",
    "\n",
    "        test_preds = np.concatenate(test_preds)\n",
    "        test_preds = (test_preds > 0.5).astype(int)\n",
    "        test_labels = np.concatenate(test_labels)\n",
    "        \n",
    "        test_accuracy = accuracy_score(test_labels, test_preds)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1:02d}/{num_epochs}], Training Loss: {avg_loss:.4f}, Testing accuracy: {test_accuracy:.4f}') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07c800f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"word2vec_lstm.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b207ae06",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2434115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "train_preds = []\n",
    "train_labels = []\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "manual_preds = []\n",
    "manual_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for batch in train_dataloader:\n",
    "        embedding, labels = batch\n",
    "        embedding = embedding.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(embedding)\n",
    "\n",
    "        train_preds.append(outputs.cpu().numpy())\n",
    "        train_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    for batch in val_dataloader:\n",
    "        embedding, labels = batch\n",
    "        embedding = embedding.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(embedding)\n",
    "\n",
    "        test_preds.append(outputs.cpu().numpy())\n",
    "        test_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    for batch in manual_dataloader:\n",
    "        embedding, labels = batch\n",
    "        embedding = embedding.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(embedding)\n",
    "\n",
    "        manual_preds.append(outputs.cpu().numpy())\n",
    "        manual_labels.append(labels.cpu().numpy())\n",
    "\n",
    "train_preds = np.concatenate(train_preds)\n",
    "train_labels = np.concatenate(train_labels)\n",
    "test_preds = np.concatenate(test_preds)\n",
    "test_labels = np.concatenate(test_labels)\n",
    "manual_preds = np.concatenate(manual_preds)\n",
    "manual_labels = np.concatenate(manual_labels)\n",
    "\n",
    "train_preds = (train_preds > 0.5).astype(int)\n",
    "test_preds = (test_preds > 0.5).astype(int)\n",
    "manual_preds = (manual_preds > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6177f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "Accuracy: 0.9942\n",
      "Precision: 0.9942\n",
      "Recall: 0.9942\n",
      "F-score: 0.9942\n",
      "===\n",
      "Testing Set\n",
      "Accuracy: 0.9753\n",
      "Precision: 0.9756\n",
      "Recall: 0.9751\n",
      "F-score: 0.9753\n",
      "===\n",
      "Manual Set\n",
      "Accuracy: 0.9750\n",
      "Precision: 0.9762\n",
      "Recall: 0.9750\n",
      "F-score: 0.9750\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(train_labels, train_preds)\n",
    "precision, recall, f_score, _ = precision_recall_fscore_support(\n",
    "        train_labels, train_preds, average=\"macro\")\n",
    "        \n",
    "print('Training Set')\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F-score: {f_score:.4f}')\n",
    "print('===')\n",
    "\n",
    "accuracy = accuracy_score(test_labels, test_preds)\n",
    "precision, recall, f_score, _ = precision_recall_fscore_support(\n",
    "        test_labels, test_preds, average=\"macro\")\n",
    "        \n",
    "print('Testing Set')\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F-score: {f_score:.4f}')\n",
    "print('===')\n",
    "\n",
    "accuracy = accuracy_score(manual_labels, manual_preds)\n",
    "precision, recall, f_score, _ = precision_recall_fscore_support(\n",
    "        manual_labels, manual_preds, average=\"macro\")\n",
    "        \n",
    "print('Manual Set')\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F-score: {f_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dc111db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>source</th>\n",
       "      <th>labels</th>\n",
       "      <th>answers</th>\n",
       "      <th>q</th>\n",
       "      <th>a</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>can animals really predict natural disasters, ...</td>\n",
       "      <td>science</td>\n",
       "      <td>1</td>\n",
       "      <td>it is a common belief that some animals can pr...</td>\n",
       "      <td>[can, animals, really, predict, natural, disas...</td>\n",
       "      <td>[it, is, a, common, belief, that, some, animal...</td>\n",
       "      <td>[[1.512847900390625, 1.3490185737609863, -1.43...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question   source  labels   \n",
       "38  can animals really predict natural disasters, ...  science       1  \\\n",
       "\n",
       "                                              answers   \n",
       "38  it is a common belief that some animals can pr...  \\\n",
       "\n",
       "                                                    q   \n",
       "38  [can, animals, really, predict, natural, disas...  \\\n",
       "\n",
       "                                                    a   \n",
       "38  [it, is, a, common, belief, that, some, animal...  \\\n",
       "\n",
       "                                            embedding  \n",
       "38  [[1.512847900390625, 1.3490185737609863, -1.43...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[idx 38]\n",
      "1\n",
      "can animals really predict natural disasters, and if so, how?\n",
      "it is a common belief that some animals can predict natural disasters, such as earthquakes or tsunamis, but the extent to which they can do so remains unclear and controversial.\n",
      "\n",
      "there is some scientific evidence to suggest that animals may be able to detect the subtle changes in the environment that precede natural disasters. for example, some animals are sensitive to changes in atmospheric pressure, electromagnetic fields, or seismic vibrations, which can occur before an earthquake or other natural disaster.\n",
      "\n",
      "some studies have reported unusual animal behavior prior to natural disasters, such as birds leaving their nests or fish swimming to the surface of the water. however, these observations are often difficult to verify and may be subject to other explanations.\n"
     ]
    }
   ],
   "source": [
    "manual_preds = manual_preds.squeeze()\n",
    "idxs = [i for i in range(40) if (manual_labels != manual_preds).tolist()[i]]\n",
    "\n",
    "display(manual_data.iloc[idxs])\n",
    "\n",
    "for idx in idxs:\n",
    "    print(f'[idx {idx}]')\n",
    "    print(manual_data.iloc[idx]['labels'])\n",
    "    print(manual_data.iloc[idx]['question'])\n",
    "    print(manual_data.iloc[idx]['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0b64bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook word2vec_lstm.ipynb to html\n",
      "[NbConvertApp] Writing 665017 bytes to word2vec_lstm.html\n"
     ]
    }
   ],
   "source": [
    "! jupyter nbconvert --to html word2vec_lstm.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd877cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
